{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#important libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "#importing stopwords is optional, in this case it decreased accuracy\n",
    "from nltk.corpus import stopwords\n",
    "import itertools\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('text_emotion.csv')\n",
    "data = data.iloc[:1000,:]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopset = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "lem = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-Processing O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cleaning(text):\n",
    "    txt = str(text)\n",
    "    txt = re.sub(r\"http\\S+\", \"\", txt)\n",
    "    if len(txt) == 0:\n",
    "        return 'no text'\n",
    "    else:\n",
    "        txt = txt.split()\n",
    "        index = 0\n",
    "        for j in range(len(txt)):\n",
    "            if txt[j][0] == '@':\n",
    "                index = j\n",
    "        txt = np.delete(txt, index)\n",
    "        if len(txt) == 0:\n",
    "            return 'no text'\n",
    "        else:\n",
    "            words = txt[0]\n",
    "            for k in range(len(txt)-1):\n",
    "                words+= \" \" + txt[k+1]\n",
    "            txt = words\n",
    "            txt = re.sub(r'[^\\w]', ' ', txt)\n",
    "            if len(txt) == 0:\n",
    "                return 'no text'\n",
    "            else:\n",
    "                txt = ''.join(''.join(s)[:2] for _, s in itertools.groupby(txt))\n",
    "                txt = txt.replace(\"'\", \"\")\n",
    "                txt = nltk.tokenize.word_tokenize(txt)\n",
    "                #data.content[i] = [w for w in data.content[i] if not w in stopset]\n",
    "                for j in range(len(txt)):\n",
    "                    txt[j] = lem.lemmatize(txt[j], \"v\")\n",
    "                if len(txt) == 0:\n",
    "                    return 'no text'\n",
    "                else:\n",
    "                    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-9a2dc553be5d>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.content[i] = words\n"
     ]
    }
   ],
   "source": [
    "data['content'] = data['content'].map(lambda x: cleaning(x))\n",
    "        \n",
    "data = data.reset_index(drop=True)\n",
    "for i in range(len(data)):\n",
    "    words = data.content[i][0]\n",
    "    for j in range(len(data.content[i])-1):\n",
    "        words+= ' ' + data.content[i][j+1]\n",
    "    data.content[i] = words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = int(np.round(len(data)*0.75))\n",
    "train = data.iloc[:x,:].reset_index(drop = True)\n",
    "test = data.iloc[x:,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier as NBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-b26c62af31fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNBC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_corpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_corpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Conda\\lib\\site-packages\\textblob\\classifiers.py\u001b[0m in \u001b[0;36maccuracy\u001b[1;34m(self, test_set, format)\u001b[0m\n\u001b[0;32m    265\u001b[0m             \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mtest_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Conda\\lib\\site-packages\\textblob\\decorators.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Conda\\lib\\site-packages\\textblob\\classifiers.py\u001b[0m in \u001b[0;36mclassifier\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;34m\"\"\"The classifier.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# nltk_class has not been defined\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m             raise ValueError(\"NLTKClassifier must have a nltk_class\"\n",
      "\u001b[1;32mE:\\Conda\\lib\\site-packages\\textblob\\classifiers.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \"\"\"\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m             self.classifier = self.nltk_class.train(self.train_features,\n\u001b[0m\u001b[0;32m    235\u001b[0m                                                     *args, **kwargs)\n\u001b[0;32m    236\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Conda\\lib\\site-packages\\nltk\\classify\\naivebayes.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(cls, labeled_featuresets, estimator)\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m                 \u001b[1;31m# Increment freq(fval|label, fname)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m                 \u001b[0mfeature_freqdist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfval\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m                 \u001b[1;31m# Record that fname can take the value fval.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m                 \u001b[0mfeature_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Conda\\lib\\collections\\__init__.py\u001b[0m in \u001b[0;36m__missing__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m         \u001b[1;34m'The count of elements not in the Counter is zero.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[1;31m# Needed so that self[missing_item] does not raise KeyError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_corpus = []\n",
    "\n",
    "for k in range(len(train)):\n",
    "    training_corpus.append((train.content[k], train.sentiment[k]))    \n",
    "test_corpus = []\n",
    "\n",
    "for l in range(len(test)):\n",
    "    test_corpus.append((test.content[l], test.sentiment[l]))\n",
    "\n",
    "model = NBC(training_corpus)\n",
    "\n",
    "print(model.accuracy(test_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00        13\n",
      "     boredom       0.00      0.00      0.00        20\n",
      "       empty       0.00      0.00      0.00        51\n",
      "  enthusiasm       0.00      0.00      0.00        44\n",
      "         fun       0.00      0.00      0.00        49\n",
      "   happiness       0.00      0.00      0.00       135\n",
      "        hate       0.00      0.00      0.00       118\n",
      "        love       0.00      0.00      0.00        97\n",
      "     neutral       0.28      0.23      0.26       443\n",
      "      relief       0.00      0.00      0.00        74\n",
      "     sadness       0.28      0.24      0.26       552\n",
      "    surprise       0.00      0.00      0.00       134\n",
      "       worry       0.33      0.71      0.45       770\n",
      "\n",
      "   micro avg       0.31      0.31      0.31      2500\n",
      "   macro avg       0.07      0.09      0.07      2500\n",
      "weighted avg       0.21      0.31      0.24      2500\n",
      "\n",
      "processing time: 4510.504441738129 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = []\n",
    "for m in range(len(test)):\n",
    "    predictions.append(model.classify(test.content[m]))\n",
    "print(classification_report(test.sentiment, predictions))\n",
    "    \n",
    "predictions_df = pd.DataFrame({'Content':test.content, 'Emotion_predicted':predictions, 'Emotion_actual':test.sentiment})\n",
    "predictions_df.to_csv('naive_emotion_recognizer.csv', index = False)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print (\"processing time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Emotion_predicted</th>\n",
       "      <th>Emotion_actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sit in altanta It s rain in boston Yay for fly...</td>\n",
       "      <td>worry</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unfortunately no</td>\n",
       "      <td>neutral</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i m try in lot of pain though</td>\n",
       "      <td>worry</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bro Martin I need you to repent Pam say we be ...</td>\n",
       "      <td>worry</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>woow I wan na join the maseera but on bed rest...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I can never clean as much of my house as I wan...</td>\n",
       "      <td>worry</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>young lady in the local Chinese take order be ...</td>\n",
       "      <td>worry</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I don t even look at their fabric unless I nee...</td>\n",
       "      <td>worry</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>It mean quot luv ya quot in Zulu Xhosa Probabl...</td>\n",
       "      <td>worry</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How inconsiderate</td>\n",
       "      <td>neutral</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I know that feel</td>\n",
       "      <td>worry</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>in the friendly game one asshole hit me in the...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>paisley have one of those cone things around h...</td>\n",
       "      <td>worry</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>be so sad about the no touch rule You still ge...</td>\n",
       "      <td>worry</td>\n",
       "      <td>enthusiasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>yeah man they bring it back on the market a co...</td>\n",
       "      <td>worry</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dont depress me I have the mother in law stay ...</td>\n",
       "      <td>worry</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sorry but I m not impress in the slightest b c...</td>\n",
       "      <td>worry</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The LG KC910 touchscreen fone be such a pile o...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>why be it so cold</td>\n",
       "      <td>worry</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I wana be there num 1 fan sharsies</td>\n",
       "      <td>worry</td>\n",
       "      <td>enthusiasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>of you Katy Perry</td>\n",
       "      <td>neutral</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>you re surround by them I have no official nie...</td>\n",
       "      <td>worry</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>freeze and rain here</td>\n",
       "      <td>sadness</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>become edgy bcause the lappy have not arrive yet</td>\n",
       "      <td>neutral</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>favorite local place bite the dust Con Sabor C...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>I take pics but I cant find my camera chord to...</td>\n",
       "      <td>worry</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>haha well i be at my friend s party but then i...</td>\n",
       "      <td>worry</td>\n",
       "      <td>fun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>just saw a pony that use to live in front of m...</td>\n",
       "      <td>worry</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>unaffected warpdesign cianan Byebye web buddie...</td>\n",
       "      <td>worry</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>I just find out 5 minutes ago mama say his spe...</td>\n",
       "      <td>worry</td>\n",
       "      <td>enthusiasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>he could be talk to me he s probably not though</td>\n",
       "      <td>worry</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>indeed much fail</td>\n",
       "      <td>neutral</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>minibar listen to politics maybe some tech sta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>to meet Jeff Hardy and Beth Britt So bad its S...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>enthusiasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>there aren t anymore exams but there be only 3...</td>\n",
       "      <td>worry</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>be not work hmph Can t upload photos to Facebook</td>\n",
       "      <td>worry</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>in previous post to timer job should be I d re...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>the grandparents in Manhattan and drop off my ...</td>\n",
       "      <td>worry</td>\n",
       "      <td>fun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>hahah me too Except for when Haley get hit by ...</td>\n",
       "      <td>worry</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>I be waste my time fail</td>\n",
       "      <td>sadness</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>It be AMAZING Its gon na get scratch soo much ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>tire amp ready for bed Really in the mood for ...</td>\n",
       "      <td>worry</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>Sounds like a nice relax afternoon I have to m...</td>\n",
       "      <td>worry</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>on homework</td>\n",
       "      <td>worry</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>back to my house to pick up some dvds for bapa...</td>\n",
       "      <td>worry</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>Going To Be A Busy Day And That Sucks Cause I ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>DAMN dude dia 06 20 e 27 eu tenho curso na DRC...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>only thing I hate about Playoff Pens hockey be...</td>\n",
       "      <td>worry</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>great Tampa people anybody in the area know so...</td>\n",
       "      <td>worry</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2489</th>\n",
       "      <td>I VOTED do u have a personal myspace i keep ta...</td>\n",
       "      <td>worry</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>cba with out</td>\n",
       "      <td>worry</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>read something happy</td>\n",
       "      <td>worry</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>tonight idkk ughh</td>\n",
       "      <td>sadness</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>this be my Ohio be for lovers tattoo get the d...</td>\n",
       "      <td>worry</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>Drivers Ed then dance</td>\n",
       "      <td>worry</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>sadly sit at home when she could be go to a pa...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>I have try He doesn t want to listen I don t k...</td>\n",
       "      <td>worry</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>lucky bitch haha we have COLDD rain up here in...</td>\n",
       "      <td>worry</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>fuck hard right now this be annoy</td>\n",
       "      <td>worry</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>Wishing I could kidnap from work</td>\n",
       "      <td>worry</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Content Emotion_predicted  \\\n",
       "0     sit in altanta It s rain in boston Yay for fly...             worry   \n",
       "1                                      Unfortunately no           neutral   \n",
       "2                         i m try in lot of pain though             worry   \n",
       "3     Bro Martin I need you to repent Pam say we be ...             worry   \n",
       "4     woow I wan na join the maseera but on bed rest...           sadness   \n",
       "5     I can never clean as much of my house as I wan...             worry   \n",
       "6     young lady in the local Chinese take order be ...             worry   \n",
       "7     I don t even look at their fabric unless I nee...             worry   \n",
       "8     It mean quot luv ya quot in Zulu Xhosa Probabl...             worry   \n",
       "9                                     How inconsiderate           neutral   \n",
       "10                                     I know that feel             worry   \n",
       "11    in the friendly game one asshole hit me in the...           sadness   \n",
       "12    paisley have one of those cone things around h...             worry   \n",
       "13    be so sad about the no touch rule You still ge...             worry   \n",
       "14    yeah man they bring it back on the market a co...             worry   \n",
       "15    dont depress me I have the mother in law stay ...             worry   \n",
       "16    sorry but I m not impress in the slightest b c...             worry   \n",
       "17    The LG KC910 touchscreen fone be such a pile o...           sadness   \n",
       "18                                    why be it so cold             worry   \n",
       "19                   I wana be there num 1 fan sharsies             worry   \n",
       "20                                    of you Katy Perry           neutral   \n",
       "21    you re surround by them I have no official nie...             worry   \n",
       "22                                 freeze and rain here           sadness   \n",
       "23     become edgy bcause the lappy have not arrive yet           neutral   \n",
       "24    favorite local place bite the dust Con Sabor C...           sadness   \n",
       "25    I take pics but I cant find my camera chord to...             worry   \n",
       "26    haha well i be at my friend s party but then i...             worry   \n",
       "27    just saw a pony that use to live in front of m...             worry   \n",
       "28    unaffected warpdesign cianan Byebye web buddie...             worry   \n",
       "29    I just find out 5 minutes ago mama say his spe...             worry   \n",
       "...                                                 ...               ...   \n",
       "2470    he could be talk to me he s probably not though             worry   \n",
       "2471                                   indeed much fail           neutral   \n",
       "2472  minibar listen to politics maybe some tech sta...           neutral   \n",
       "2473  to meet Jeff Hardy and Beth Britt So bad its S...           neutral   \n",
       "2474  there aren t anymore exams but there be only 3...             worry   \n",
       "2475   be not work hmph Can t upload photos to Facebook             worry   \n",
       "2476  in previous post to timer job should be I d re...           neutral   \n",
       "2477  the grandparents in Manhattan and drop off my ...             worry   \n",
       "2478  hahah me too Except for when Haley get hit by ...             worry   \n",
       "2479                            I be waste my time fail           sadness   \n",
       "2480  It be AMAZING Its gon na get scratch soo much ...           sadness   \n",
       "2481  tire amp ready for bed Really in the mood for ...             worry   \n",
       "2482  Sounds like a nice relax afternoon I have to m...             worry   \n",
       "2483                                        on homework             worry   \n",
       "2484  back to my house to pick up some dvds for bapa...             worry   \n",
       "2485  Going To Be A Busy Day And That Sucks Cause I ...           sadness   \n",
       "2486  DAMN dude dia 06 20 e 27 eu tenho curso na DRC...           neutral   \n",
       "2487  only thing I hate about Playoff Pens hockey be...             worry   \n",
       "2488  great Tampa people anybody in the area know so...             worry   \n",
       "2489  I VOTED do u have a personal myspace i keep ta...             worry   \n",
       "2490                                       cba with out             worry   \n",
       "2491                               read something happy             worry   \n",
       "2492                                  tonight idkk ughh           sadness   \n",
       "2493  this be my Ohio be for lovers tattoo get the d...             worry   \n",
       "2494                              Drivers Ed then dance             worry   \n",
       "2495  sadly sit at home when she could be go to a pa...           sadness   \n",
       "2496  I have try He doesn t want to listen I don t k...             worry   \n",
       "2497  lucky bitch haha we have COLDD rain up here in...             worry   \n",
       "2498                  fuck hard right now this be annoy             worry   \n",
       "2499                   Wishing I could kidnap from work             worry   \n",
       "\n",
       "     Emotion_actual  \n",
       "0           neutral  \n",
       "1             worry  \n",
       "2           neutral  \n",
       "3             worry  \n",
       "4             worry  \n",
       "5             worry  \n",
       "6          surprise  \n",
       "7              hate  \n",
       "8           neutral  \n",
       "9             empty  \n",
       "10          neutral  \n",
       "11             hate  \n",
       "12            worry  \n",
       "13       enthusiasm  \n",
       "14            worry  \n",
       "15          sadness  \n",
       "16          sadness  \n",
       "17             hate  \n",
       "18          sadness  \n",
       "19       enthusiasm  \n",
       "20             love  \n",
       "21          sadness  \n",
       "22          neutral  \n",
       "23          sadness  \n",
       "24          sadness  \n",
       "25            worry  \n",
       "26              fun  \n",
       "27          neutral  \n",
       "28            worry  \n",
       "29       enthusiasm  \n",
       "...             ...  \n",
       "2470        sadness  \n",
       "2471          worry  \n",
       "2472        neutral  \n",
       "2473     enthusiasm  \n",
       "2474          worry  \n",
       "2475          worry  \n",
       "2476        neutral  \n",
       "2477            fun  \n",
       "2478        sadness  \n",
       "2479          worry  \n",
       "2480        neutral  \n",
       "2481        neutral  \n",
       "2482      happiness  \n",
       "2483        neutral  \n",
       "2484        neutral  \n",
       "2485        sadness  \n",
       "2486        neutral  \n",
       "2487           hate  \n",
       "2488       surprise  \n",
       "2489          worry  \n",
       "2490          worry  \n",
       "2491        neutral  \n",
       "2492        neutral  \n",
       "2493        sadness  \n",
       "2494        neutral  \n",
       "2495        sadness  \n",
       "2496          worry  \n",
       "2497        neutral  \n",
       "2498          anger  \n",
       "2499           hate  \n",
       "\n",
       "[2500 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
